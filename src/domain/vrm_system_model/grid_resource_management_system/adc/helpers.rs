use std::{
    cmp::Ordering,
    collections::HashMap,
    time::{SystemTime, UNIX_EPOCH},
};

use crate::domain::vrm_system_model::{
    grid_resource_management_system::{
        adc::ADC, order_res_vrm_component_database::OrderResVrmComponentDatabase, vrm_component_manager::DUMMY_COMPONENT_ID,
        vrm_component_order::VrmComponentOrder, vrm_component_registry::vrm_component_proxy::VrmComponentProxy, vrm_component_trait::VrmComponent,
    },
    reservation::{reservation::ReservationState, reservation_store::ReservationId},
    utils::{
        id::{ComponentId, ReservationName, ShadowScheduleId},
        statistics::ANALYTICS_TARGET,
    },
};

impl ADC {
    /// Orchestrates the Shadow Scheduling process to optimize system utilization.
    ///
    /// This function performs the 4-step process requested:
    /// 1. Check satisfaction.
    /// 2. Create shadow schedule.
    /// 3. Reschedule reservations (Delete & Re-Reserve in Shadow).
    /// 4. Commit if better.
    pub fn optimize_schedule(&mut self) {
        // (1) Init shadow scheduling if system satisfaction is worse than threshold
        // Satisfaction Index: 0.0 (Optimal) -> 1.0 (Fragmented)
        // If fragmentation is high (> 0.5), we try to optimize.
        let current_satisfaction = self.manager.get_system_satisfaction(None);
        if current_satisfaction > 0.5 {
            let shadow_id = ShadowScheduleId::new("optimization_run".to_string());

            // (2) Create shadow schedule
            if self.manager.create_shadow_schedule(shadow_id.clone()) {
                // (3) Reschedule all reserved Reservation
                // Strategy: Clear the shadow schedule and re-insert tasks sorted by duration (Longest Task First).

                // A. Collect all active reservation IDs currently managed
                let active_ids: Vec<ReservationId> = self.manager.res_to_vrm_component.keys().cloned().collect();

                // B. Sort them by duration (Longest First Heuristic)
                let mut sorted_ids = active_ids.clone();
                sorted_ids.sort_by(|a, b| {
                    let dur_a = self.reservation_store.get_task_duration(*a);
                    let dur_b = self.reservation_store.get_task_duration(*b);
                    dur_b.cmp(&dur_a) // Descending
                });

                // C. Delete them from the Shadow Schedule context
                for res_id in &active_ids {
                    // This removes them from the underlying components in the shadow world
                    self.manager.delete_task_at_component(*res_id, Some(shadow_id.clone()));

                    // Reset the state in the shadow store to 'Open' so they can be reserved again.
                    // Accessing the shadow store via the manager.
                    if let Some((_, store)) = self.manager.shadow_schedule_reservations.get_mut(&shadow_id) {
                        store.update_state(*res_id, ReservationState::Open);
                    }
                }

                // D. Re-reserve them in the Shadow Schedule context
                for res_id in sorted_ids {
                    self.manager.reserve_task_at_best_vrm_component(
                        res_id,
                        Some(shadow_id.clone()),
                        &mut HashMap::new(), // dummy db for internal tracking
                        VrmComponentOrder::OrderStartFirst,
                        |_, _| Ordering::Equal,
                    );
                }

                // (4) Commit ShadowSchedule as the new master schedule if better
                let new_satisfaction = self.manager.get_system_satisfaction(Some(shadow_id.clone()));

                // Lower satisfaction index means less fragmentation/better schedule
                if new_satisfaction < current_satisfaction {
                    log::info!(
                        "Shadow Optimization Successful: Improved satisfaction from {} to {}. Committing.",
                        current_satisfaction,
                        new_satisfaction
                    );
                    self.manager.commit_shadow_schedule(shadow_id);
                } else {
                    log::info!("Shadow Optimization Discarded: No improvement ({} vs {}). Rolling back.", new_satisfaction, current_satisfaction);
                    self.manager.delete_shadow_schedule(shadow_id);
                }
            }
        }
    }

    // TODO Should work with GridComponent
    /// Removes an VrmComponent from the registry based on its unique identifier.
    fn delete_vrm_component(&mut self, vrm_component: Box<dyn VrmComponent>) -> bool {
        log::debug!("ACD {} deletes VrmComponent {}", self.id, vrm_component.get_id());
        return self.manager.delete_vrm_component(vrm_component.get_id());
    }

    /// Adds a new `GridComponent` to the domain and initializes its local schedule view.
    fn add_vrm_component(&mut self, vrm_component: VrmComponentProxy) -> bool {
        log::debug!("ADC: {} adds AcI: {}", self.id, vrm_component.get_id());
        return self.manager.add_vrm_component(
            vrm_component,
            self.simulator.clone_box().into(),
            self.reservation_store.clone(),
            self.num_of_slots,
            self.slot_width,
        );
    }

    fn reserve_commit(reservation_id: ReservationId) {
        todo!()
    }

    fn reserve_probe(reservation_id: ReservationId) {
        todo!()
    }

    fn reserve_reserve(reservation_id: ReservationId) {
        todo!()
    }

    /// Submits a task to the first VrmComponent that accepts the reservation based on the defined `VrmComponentOrder`.
    ///
    /// Updates the `TODO` to maintain the mapping between the
    /// reservation and the component that accepted it.
    pub fn submit_task_at_first_grid_component(
        &mut self,
        reservation_id: ReservationId,
        shadow_schedule_id: Option<ShadowScheduleId>,
        grid_component_res_database: &mut HashMap<ReservationId, ComponentId>,
    ) -> ReservationId {
        // Wrong order
        for component_id in self.manager.get_ordered_vrm_components(self.vrm_component_order) {
            // TODO Change, if communication with aci is over the network
            let res_snapshot = self.reservation_store.get_reservation_snapshot(reservation_id).unwrap();

            if self.manager.can_component_handel(component_id.clone(), res_snapshot) {
                let reserve_res_id = self.manager.reserve(component_id.clone(), reservation_id, shadow_schedule_id.clone());

                if self.reservation_store.is_reservation_state_at_least(reserve_res_id, ReservationState::ReserveAnswer) {
                    // Register new schedule Sub-Task
                    // Update grid_component_res_database for rollback and for ADC to keep track
                    // Update local WorkflowScheduler Log (for rollback and later merge)
                    if grid_component_res_database.contains_key(&reserve_res_id) {
                        log::error!(
                            "ErrorReservationWasReservedInMultipleGridComponents: The reservation {:?} was multiple times to the GirdComponent {} submitted.",
                            self.reservation_store.get_name_for_key(reserve_res_id),
                            component_id
                        );
                    }
                    grid_component_res_database.insert(reserve_res_id, component_id.clone());

                    // Update VrmComponent's local view (schedule) of the underlying VrmComponents
                    self.manager.reserve_without_check(component_id.clone(), reserve_res_id);

                    if !self.reservation_store.is_reservation_state_at_least(reserve_res_id, ReservationState::ReserveAnswer) {
                        log::error!("Reserve of reservation {:?} in local schedule copy of Grid Component {} failed.", reserve_res_id, component_id);
                    }

                    return reserve_res_id;
                }
            }
        }
        self.reservation_store.update_state(reservation_id, ReservationState::Rejected);
        return reservation_id;
    }

    /// Probes all available VrmComponents and selects the best candidate based on the provided comparison function.
    ///
    /// This implements a "Best Fit" strategy, useful for optimizing resource utilization or
    /// meeting Earliest Finish Time (EFT) constraints.
    /// TODO should be moved to VrmComponentManager
    pub fn submit_task_at_best_vrm_component<F>(
        &mut self,
        reservation_id: ReservationId,
        shadow_schedule_id: Option<ShadowScheduleId>,
        grid_component_res_database: &mut HashMap<ReservationId, ComponentId>,
        reservation_order: F,
    ) -> Option<ReservationId>
    where
        F: Fn(ReservationId, ReservationId) -> Ordering + 'static,
    {
        let mut order_grid_component_res_database = OrderResVrmComponentDatabase::new(reservation_order, self.vrm_component_order.get_comparator());

        for component_id in self.manager.get_random_ordered_vrm_components() {
            let res_snapshot = self.reservation_store.get_reservation_snapshot(reservation_id).unwrap();

            if self.manager.can_component_handel(component_id.clone(), res_snapshot) {
                let probe_reservations = self.manager.get_vrm_component_mut(component_id.clone()).probe(reservation_id, shadow_schedule_id.clone());

                // Do not trust answer of lower GridComponent
                // Validation of probe answers
                for prob_reservation_id in probe_reservations.get_ids() {
                    if self.reservation_store.get_assigned_start(prob_reservation_id)
                        < self.reservation_store.get_booking_interval_start(prob_reservation_id)
                        || self.reservation_store.get_assigned_end(prob_reservation_id)
                            > self.reservation_store.get_booking_interval_end(prob_reservation_id)
                    {
                        log::error!("Invalid Answer.");
                    }
                }

                order_grid_component_res_database.put_all(probe_reservations);
            }
        }

        // Choose reservation candidate with EFT and reserve it
        for reservation_id in order_grid_component_res_database.sorted_key_set(&self.manager) {
            let component_id = order_grid_component_res_database.store.get(&reservation_id).unwrap();

            let candidate_id = self.manager.reserve(component_id.clone(), reservation_id, None);

            if self.reservation_store.is_reservation_state_at_least(candidate_id, ReservationState::ReserveAnswer) {
                // Register new schedule Sub-Task
                // Update grid_component_res_database for rollback and for ADC to keep track
                // Update Transaction Log
                if grid_component_res_database.contains_key(&candidate_id) {
                    log::error!(
                        "ErrorReservationWasReservedInMultipleGridComponents: The reservation {:?} was multiple times to the GirdComponent {} submitted.",
                        self.reservation_store.get_name_for_key(candidate_id),
                        component_id
                    );
                }
                grid_component_res_database.insert(candidate_id, component_id.clone());

                // Update local schedule
                self.manager.reserve_without_check(component_id.clone(), candidate_id);

                if self.reservation_store.is_reservation_state_at_least(candidate_id, ReservationState::ReserveAnswer) {
                    log::error!("Reserve of reservation {:?} in local schedule of GridComponent {:?} failed.", candidate_id, component_id);
                }
                return Some(candidate_id);
            }
        }

        return None;
    }

    /// Deletes a task from the underlying component and cleans up the associated local schedule.
    pub fn delete_task_at_component(
        &mut self,
        component_id: ComponentId,
        reservation_id: ReservationId,
        shadow_schedule_id: Option<ShadowScheduleId>,
    ) {
        todo!()
    }

    pub fn log_state_probe(&mut self, num_of_answers: i64, arrival_time_at_aci: i64) {
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
        let processing_time = self.simulator.get_current_time_in_ms() - arrival_time_at_aci;
        // TODO
        tracing::info!(
            target: ANALYTICS_TARGET,
            Time = now,
            Command = "Commit".to_string(),
            ProbeAnswers = num_of_answers,
            ProcessingTime = processing_time,
        );
    }

    pub fn log_stat(&mut self, command: String, reservation_id: ReservationId, arrival_time_at_aci: i64) {
        let now = SystemTime::now().duration_since(UNIX_EPOCH).unwrap().as_secs();
        let processing_time = self.simulator.get_current_time_in_ms() - arrival_time_at_aci;

        if let Some(res_handle) = self.reservation_store.get(reservation_id) {
            let (start, end, res_name, capacity, workload, state, proceeding, num_tasks) = {
                let res = res_handle.read().unwrap();

                let start = res.get_base_reservation().get_assigned_start();
                let end = res.get_base_reservation().get_assigned_end();
                let name = res.get_base_reservation().get_name().clone();
                let cap = res.get_base_reservation().get_reserved_capacity();
                let workload = res.get_base_reservation().get_task_duration() * cap;
                let state = res.get_base_reservation().get_state();
                let proceeding = res.get_base_reservation().get_reservation_proceeding();

                // TODO Java implementation also proceeded workflows if so, num_task should not be always be 1 (implement get_task_count())
                let tasks = 42;

                (start, end, name, cap, workload, state, proceeding, tasks)
            };

            let load_metric = self.manager.get_load_metric(start, end, None);

            tracing::info!(
                target: ANALYTICS_TARGET,
                Time = now,
                LogDescription = "AcI Operation finished",
                ComponentType = %self.id,
                ComponentUtilization = load_metric.utilization,
                ComponentCapacity = load_metric.possible_capacity,
                ComponentFragmentation = self.manager.get_system_satisfaction(None),
                ReservationName = %res_name,
                ReservationCapacity = capacity,
                ReservationWorkload = workload,
                ReservationState = ?state,
                ReservationProceeding = ?proceeding,
                NumberOfTasks = num_tasks,
                Command = command,
                ProcessingTime = processing_time,
            );
        } else {
            // Handling in case reservation is missing (e.g. deleted/cleaned up)

            tracing::warn!(
                target: ANALYTICS_TARGET,
                Time = now,
                LogDescription = "AcI Operation finished (Reservation Missing/Deleted)",
                ComponentType = %self.id,
                ReservationId = ?reservation_id,
                Command = command,
                ProcessingTime = processing_time,
            );
        }
    }
}
